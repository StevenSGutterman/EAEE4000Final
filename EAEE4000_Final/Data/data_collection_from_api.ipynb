{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e04b5235-26b1-4643-b2c6-4796c8a212f0",
   "metadata": {},
   "source": [
    " # ML for Environmental Engineering \n",
    " By: Suheyla Tozan and Steven Gutterman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ca6165-d9b4-478a-bb07-64fd7702def3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b605c73-27f2-4343-b5ff-16ba7e614cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracts meteorological data from 2018 to 2023 for ELABHWC. For 1993 - 2023, replace \"start_year\" with 1993\n",
    "\n",
    "start_year = 2018\n",
    "end_year = 2023\n",
    "\n",
    "#parameter codes from API, corresponding to meteorological parameters\n",
    "param_codes = [\"61103\", \"61104\", \"62101\", \"62201\", \"64101\"]\n",
    "\n",
    "date_ranges = []\n",
    "\n",
    "#loops over years to extract API URL. NOTE: the URL provided is not updated. To replicate results,\n",
    "#create your own AQS API account. However, we've made our collected datasets available for the purposes of replicating our plots.\n",
    "for year in range(start_year, end_year + 1):\n",
    "    date_range = f\"https://aqs.epa.gov/data/api/sampleData/bySite?email=s.gutterman@columbia.edu&key=indigoosprey26&param={','.join(param_codes)}&bdate={year}0101&edate={year}1231&state=06&county=037&site=1103&duration=1\"\n",
    "    date_ranges.append(date_range)\n",
    "\n",
    "combined_data = pd.DataFrame()\n",
    "\n",
    "for index, url in enumerate(date_ranges):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raises an HTTPError for bad requests\n",
    "\n",
    "        data = response.json()\n",
    "        data = data.get('Data', [])\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        df = df[df['parameter_code'].isin(param_codes)][['date_gmt', 'time_gmt', 'parameter_code', 'sample_measurement']]\n",
    "\n",
    "        for param in param_codes:\n",
    "            df_param = df[df['parameter_code'] == param].copy()\n",
    "            df_param.rename(columns={'sample_measurement': f'sample_measurement_{param}'}, inplace=True)\n",
    "            df_param.drop('parameter_code', axis=1, inplace=True)\n",
    "\n",
    "            if combined_data.empty:\n",
    "                combined_data = df_param\n",
    "            else:\n",
    "                combined_data = pd.merge(combined_data, df_param, on=['date_gmt', 'time_gmt'], how='outer')\n",
    "\n",
    "        print(f\"Successfully added data from {url} (File {index + 1} of {len(date_ranges)})\")\n",
    "\n",
    "        # Wait for 10 seconds before processing the next URL\n",
    "        time.sleep(10)\n",
    "\n",
    "    except requests.HTTPError as http_err:\n",
    "        print(f\"HTTP error occurred while fetching data from {url}: {http_err}\")\n",
    "    except Exception as err:\n",
    "        print(f\"An error occurred while fetching data from {url}: {err}\")\n",
    "\n",
    "# Save the combined data to an Excel file\n",
    "combined_data.to_excel(\"metdata_2018-2023_ELABHWC\", index=False)\n",
    "\n",
    "print(\"All data has been successfully compiled into the Excel file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b0b902-aa77-4510-9191-e5f2f4a4d8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now collecting criteria gas concentration data\n",
    "\n",
    "start_year = 2018\n",
    "end_year = 2023\n",
    "\n",
    "#parameter codes from API, corresponding to criteria gas concentration parameters\n",
    "param_codes = [\"42101\", \"42602\", \"42401\", \"44201\"]\n",
    "\n",
    "date_ranges = []\n",
    "\n",
    "#loops over years to extract API URL. NOTE: the URL provided is not updated. To replicate results,\n",
    "#create your own AQS API account. However, we've made our collected datasets available for the purposes of replicating our plots.\n",
    "for year in range(start_year, end_year + 1):\n",
    "    date_range = f\"https://aqs.epa.gov/data/api/sampleData/bySite?email=s.gutterman@columbia.edu&key=indigoosprey26&param={','.join(param_codes)}&bdate={year}0101&edate={year}1231&state=06&county=037&site=1103&duration=1\"\n",
    "    date_ranges.append(date_range)\n",
    "\n",
    "combined_data = pd.DataFrame()\n",
    "\n",
    "for index, url in enumerate(date_ranges):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        data = response.json()\n",
    "        data = data.get('Data', [])\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        df = df[df['parameter_code'].isin(param_codes)][['date_gmt', 'time_gmt', 'parameter_code', 'sample_measurement']]\n",
    "\n",
    "        for param in param_codes:\n",
    "            df_param = df[df['parameter_code'] == param].copy()\n",
    "            df_param.rename(columns={'sample_measurement': f'sample_measurement_{param}'}, inplace=True)\n",
    "            df_param.drop('parameter_code', axis=1, inplace=True)\n",
    "\n",
    "            if combined_data.empty:\n",
    "                combined_data = df_param\n",
    "            else:\n",
    "                combined_data = pd.merge(combined_data, df_param, on=['date_gmt', 'time_gmt'], how='outer')\n",
    "\n",
    "        print(f\"Successfully added data from {url} (File {index + 1} of {len(date_ranges)})\")\n",
    "\n",
    "        time.sleep(10)\n",
    "\n",
    "    except requests.HTTPError as http_err:\n",
    "        print(f\"HTTP error occurred while fetching data from {url}: {http_err}\")\n",
    "    except Exception as err:\n",
    "        print(f\"An error occurred while fetching data from {url}: {err}\")\n",
    "\n",
    "combined_data.to_excel(\"criteriagasdata_2018-2023_ELABHWC.xlsx\", index=False)\n",
    "\n",
    "print(\"All data has been successfully compiled into the Excel file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a67637-21fe-4672-bb5d-44c03d674e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this cell consolidates and cleans up columns, shown is for the meteorological parameters, but replace\n",
    "#file_path and param_codes to consolidate/clean up criteria gas data\n",
    "\n",
    "file_path = \"metdata_2018-2023_ELABHWC.xlsx\"\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "param_codes = [\"61103\", \"61104\", \"62101\", \"62201\", \"64101\"]\n",
    "\n",
    "for param in param_codes:\n",
    "    param_columns = [col for col in data.columns if f'sample_measurement_{param}' in col and col != f'sample_measurement_{param}']\n",
    "\n",
    "    if param_columns:\n",
    "        data[f'sample_measurement_{param}'] = data[param_columns].max(axis=1, skipna=True)\n",
    "\n",
    "        data.drop(columns=param_columns, inplace=True)\n",
    "\n",
    "final_columns = ['date_gmt', 'time_gmt'] + [f'sample_measurement_{param}' for param in param_codes]\n",
    "data = data[final_columns]\n",
    "\n",
    "data.to_excel(\"metdata_2018-2023_ELABHWC.xlsx\", index=False)\n",
    "\n",
    "print(\"Data has been successfully consolidated into the new Excel file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083a5a5f-13c5-418b-b1ba-3b9425b85efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this cell removes duplicate column names for \"date_gmt\" and \"time_gmt\"\n",
    "#shown is for criteria gas data, but replace with meteorological data to do both\n",
    "file_path = 'criteriagasdata_2018-2023_ELABHWC.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "df_cleaned = df.drop_duplicates(subset=['date_gmt', 'time_gmt'])\n",
    "\n",
    "df_cleaned.to_excel('criteriagasdata_2018-2023_ELABHWC.xlsx', index=False)\n",
    "\n",
    "print(\"Duplicate rows based on the first two columns have been removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014e2caa-c8de-4726-aeb7-aa7839749a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
